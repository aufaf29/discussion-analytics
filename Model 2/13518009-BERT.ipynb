{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e6ff08",
   "metadata": {
    "papermill": {
     "duration": 0.029393,
     "end_time": "2021-11-16T15:10:08.964266",
     "exception": false,
     "start_time": "2021-11-16T15:10:08.934873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f506b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:09.041440Z",
     "iopub.status.busy": "2021-11-16T15:10:09.038582Z",
     "iopub.status.idle": "2021-11-16T15:10:16.354131Z",
     "shell.execute_reply": "2021-11-16T15:10:16.354727Z",
     "shell.execute_reply.started": "2021-11-16T15:06:44.752432Z"
    },
    "papermill": {
     "duration": 7.362168,
     "end_time": "2021-11-16T15:10:16.355006",
     "exception": false,
     "start_time": "2021-11-16T15:10:08.992838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /usr/share/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, initializers, regularizers, constraints, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, Embedding, Dropout, GlobalMaxPool1D, SpatialDropout1D, BatchNormalization, Bidirectional, LSTM, GlobalMaxPooling1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964665b",
   "metadata": {
    "papermill": {
     "duration": 0.025227,
     "end_time": "2021-11-16T15:10:16.406289",
     "exception": false,
     "start_time": "2021-11-16T15:10:16.381062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utility Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9786b6",
   "metadata": {
    "papermill": {
     "duration": 0.024996,
     "end_time": "2021-11-16T15:10:16.456218",
     "exception": false,
     "start_time": "2021-11-16T15:10:16.431222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef0f65b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:16.513004Z",
     "iopub.status.busy": "2021-11-16T15:10:16.512089Z",
     "iopub.status.idle": "2021-11-16T15:10:16.515627Z",
     "shell.execute_reply": "2021-11-16T15:10:16.515034Z",
     "shell.execute_reply.started": "2021-11-16T15:06:51.297407Z"
    },
    "papermill": {
     "duration": 0.034333,
     "end_time": "2021-11-16T15:10:16.515758",
     "exception": false,
     "start_time": "2021-11-16T15:10:16.481425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label_encoding(label):\n",
    "    if(label == 'fact-based'):\n",
    "        return 0\n",
    "    elif(label == 'feeling-based'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debf874c",
   "metadata": {
    "papermill": {
     "duration": 0.02518,
     "end_time": "2021-11-16T15:10:16.565969",
     "exception": false,
     "start_time": "2021-11-16T15:10:16.540789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preprocessing\n",
    "\n",
    "Tahap preprocessing akan mengubah kalimat menjadi format yang lebih sederhana dan general. Beberapa preprocessing yang dilakukan adalah membuat lowercase, menyaring karakter, dan melakukan lemmatisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b51ed4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:16.629743Z",
     "iopub.status.busy": "2021-11-16T15:10:16.628708Z",
     "iopub.status.idle": "2021-11-16T15:10:16.631930Z",
     "shell.execute_reply": "2021-11-16T15:10:16.631383Z",
     "shell.execute_reply.started": "2021-11-16T15:06:51.307155Z"
    },
    "papermill": {
     "duration": 0.040898,
     "end_time": "2021-11-16T15:10:16.632093",
     "exception": false,
     "start_time": "2021-11-16T15:10:16.591195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "    \n",
    "def lemmatize_sentence(sentence):\n",
    "\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    \n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "def sentence_pos_tag(sentence):\n",
    "    text = word_tokenize(sentence)\n",
    "    pos_tag = nltk.pos_tag(text)\n",
    "    pos_tag_res = ''\n",
    "    for i in range(len(pos_tag)):\n",
    "        pos_tag_res += pos_tag[i][1]\n",
    "        pos_tag_res += ' ' if i != len(sentence)-1 else '' \n",
    "    return pos_tag_res\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\" \\d+ \", \" \", text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = re.sub(r\"[^a-z ]\", \"\", text)\n",
    "    text = re.sub(r\"  \", \" \", text)\n",
    "    text = lemmatize_sentence(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e13a1",
   "metadata": {
    "papermill": {
     "duration": 0.02402,
     "end_time": "2021-11-16T15:10:16.681409",
     "exception": false,
     "start_time": "2021-11-16T15:10:16.657389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f37433",
   "metadata": {
    "papermill": {
     "duration": 0.024845,
     "end_time": "2021-11-16T15:10:16.732111",
     "exception": false,
     "start_time": "2021-11-16T15:10:16.707266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load Preprocessed Data\n",
    "\n",
    "Untuk mempercepat dan mengurangi beban komputasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2ed94f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:16.787218Z",
     "iopub.status.busy": "2021-11-16T15:10:16.786401Z",
     "iopub.status.idle": "2021-11-16T15:10:16.928571Z",
     "shell.execute_reply": "2021-11-16T15:10:16.927932Z",
     "shell.execute_reply.started": "2021-11-16T15:06:51.322092Z"
    },
    "papermill": {
     "duration": 0.17188,
     "end_time": "2021-11-16T15:10:16.928723",
     "exception": false,
     "start_time": "2021-11-16T15:10:16.756843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = open(\"../input/quote-response/quotexresponseprocessed.pkl\", \"rb\")\n",
    "df = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cba7a3",
   "metadata": {
    "papermill": {
     "duration": 0.025886,
     "end_time": "2021-11-16T15:10:16.980655",
     "exception": false,
     "start_time": "2021-11-16T15:10:16.954769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepare Data\n",
    "\n",
    "Proses data yang dibutuhkan untuk training. Data quote adalah kalimat yang berisikan pernyataan yang mengangkat diskusi, dan data response merupakan argumen terhadap pernyataan yang diberikan. Data pos tag dari kalimat response menjadi salah satu fitur eksperimen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e11912c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:17.046571Z",
     "iopub.status.busy": "2021-11-16T15:10:17.045275Z",
     "iopub.status.idle": "2021-11-16T15:10:17.056544Z",
     "shell.execute_reply": "2021-11-16T15:10:17.055948Z",
     "shell.execute_reply.started": "2021-11-16T15:06:51.465934Z"
    },
    "papermill": {
     "duration": 0.050053,
     "end_time": "2021-11-16T15:10:17.056680",
     "exception": false,
     "start_time": "2021-11-16T15:10:17.006627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[df['emotion_fact'] != 'unsure']\n",
    "df = df.loc[:, ['presented_quote', 'presented_response', 'emotion_fact', 'presented_response_tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b41736af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:17.120371Z",
     "iopub.status.busy": "2021-11-16T15:10:17.119064Z",
     "iopub.status.idle": "2021-11-16T15:10:17.121716Z",
     "shell.execute_reply": "2021-11-16T15:10:17.122304Z",
     "shell.execute_reply.started": "2021-11-16T15:06:51.486472Z"
    },
    "papermill": {
     "duration": 0.040133,
     "end_time": "2021-11-16T15:10:17.122477",
     "exception": false,
     "start_time": "2021-11-16T15:10:17.082344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['presented_quote'] = df['presented_quote'].apply(lambda x: preprocessing(x))\n",
    "# df['presented_response'] = df['presented_response'].apply(lambda x: preprocessing(x))\n",
    "df['emotion_fact'] = df['emotion_fact'].apply(lambda x: label_encoding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a559136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:17.181666Z",
     "iopub.status.busy": "2021-11-16T15:10:17.180578Z",
     "iopub.status.idle": "2021-11-16T15:10:17.197905Z",
     "shell.execute_reply": "2021-11-16T15:10:17.198582Z",
     "shell.execute_reply.started": "2021-11-16T15:06:51.497578Z"
    },
    "papermill": {
     "duration": 0.050802,
     "end_time": "2021-11-16T15:10:17.198736",
     "exception": false,
     "start_time": "2021-11-16T15:10:17.147934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>presented_quote</th>\n",
       "      <th>presented_response</th>\n",
       "      <th>emotion_fact</th>\n",
       "      <th>presented_response_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i get a good idea however they do tend to stay...</td>\n",
       "      <td>by your own admission you havent hang out with...</td>\n",
       "      <td>1</td>\n",
       "      <td>IN PRP$ JJ NN PRP VBP VB RP IN NN IN DT NN CC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one of the big argument against gun control be...</td>\n",
       "      <td>not quite to be more correct regard government...</td>\n",
       "      <td>0</td>\n",
       "      <td>RB RB TO VB RBR JJ JJ NN CC VB DT NN TO VB NN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there be some incedents that be beyond your co...</td>\n",
       "      <td>well yes</td>\n",
       "      <td>1</td>\n",
       "      <td>RB RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>legality do not matter religous implication do...</td>\n",
       "      <td>exact to the point amp beautiful</td>\n",
       "      <td>1</td>\n",
       "      <td>NN TO DT NN NN NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>once again you seem to support the killing of ...</td>\n",
       "      <td>base on the idea that people be dispensible pa...</td>\n",
       "      <td>1</td>\n",
       "      <td>NN IN DT NN WDT NNS VB JJ RB IN PRP VBP PRP$ V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>the id movement form of id state that there be...</td>\n",
       "      <td>that of course be the logical fallacy know as ...</td>\n",
       "      <td>0</td>\n",
       "      <td>DT IN NN VB DT JJ NN VBP IN JJ NN DT NN PRP VB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>for me it would therefore have make no differe...</td>\n",
       "      <td>it logically follow from the moral foundation ...</td>\n",
       "      <td>1</td>\n",
       "      <td>PRP RB VBP IN DT JJ NN VBN RP CC PRP VBP TO JJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>good thing this argument have never be doneoh ...</td>\n",
       "      <td>and teen sex doesnt by the very nature of its ...</td>\n",
       "      <td>1</td>\n",
       "      <td>CC JJ NN NN IN DT JJ NN IN PRP$ NN NN IN NN DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>i know one thing anything that happen politica...</td>\n",
       "      <td>wasnt sinjin crow about his plan to take the f...</td>\n",
       "      <td>1</td>\n",
       "      <td>NN NN NN IN PRP$ NN TO VB DT NN NN CC NN TO DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>i enjoy botany more than most thing and i have...</td>\n",
       "      <td>hi smallax welcome to the forum i do a search ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NN VBZ JJ TO DT NN NN VBP DT NN CC VBP VBN DT ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5850 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        presented_quote  \\\n",
       "0     i get a good idea however they do tend to stay...   \n",
       "2     one of the big argument against gun control be...   \n",
       "4     there be some incedents that be beyond your co...   \n",
       "6     legality do not matter religous implication do...   \n",
       "8     once again you seem to support the killing of ...   \n",
       "...                                                 ...   \n",
       "9977  the id movement form of id state that there be...   \n",
       "9978  for me it would therefore have make no differe...   \n",
       "9979  good thing this argument have never be doneoh ...   \n",
       "9980  i know one thing anything that happen politica...   \n",
       "9981  i enjoy botany more than most thing and i have...   \n",
       "\n",
       "                                     presented_response  emotion_fact  \\\n",
       "0     by your own admission you havent hang out with...             1   \n",
       "2     not quite to be more correct regard government...             0   \n",
       "4                                              well yes             1   \n",
       "6                      exact to the point amp beautiful             1   \n",
       "8     base on the idea that people be dispensible pa...             1   \n",
       "...                                                 ...           ...   \n",
       "9977  that of course be the logical fallacy know as ...             0   \n",
       "9978  it logically follow from the moral foundation ...             1   \n",
       "9979  and teen sex doesnt by the very nature of its ...             1   \n",
       "9980  wasnt sinjin crow about his plan to take the f...             1   \n",
       "9981  hi smallax welcome to the forum i do a search ...             0   \n",
       "\n",
       "                                 presented_response_tag  \n",
       "0     IN PRP$ JJ NN PRP VBP VB RP IN NN IN DT NN CC ...  \n",
       "2     RB RB TO VB RBR JJ JJ NN CC VB DT NN TO VB NN ...  \n",
       "4                                                RB RB   \n",
       "6                                    NN TO DT NN NN NN   \n",
       "8     NN IN DT NN WDT NNS VB JJ RB IN PRP VBP PRP$ V...  \n",
       "...                                                 ...  \n",
       "9977  DT IN NN VB DT JJ NN VBP IN JJ NN DT NN PRP VB...  \n",
       "9978  PRP RB VBP IN DT JJ NN VBN RP CC PRP VBP TO JJ...  \n",
       "9979  CC JJ NN NN IN DT JJ NN IN PRP$ NN NN IN NN DT...  \n",
       "9980  NN NN NN IN PRP$ NN TO VB DT NN NN CC NN TO DT...  \n",
       "9981  NN VBZ JJ TO DT NN NN VBP DT NN CC VBP VBN DT ...  \n",
       "\n",
       "[5850 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd52491",
   "metadata": {
    "papermill": {
     "duration": 0.02548,
     "end_time": "2021-11-16T15:10:17.250048",
     "exception": false,
     "start_time": "2021-11-16T15:10:17.224568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Split Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c7e4839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:17.313115Z",
     "iopub.status.busy": "2021-11-16T15:10:17.305540Z",
     "iopub.status.idle": "2021-11-16T15:10:17.317966Z",
     "shell.execute_reply": "2021-11-16T15:10:17.317407Z",
     "shell.execute_reply.started": "2021-11-16T15:06:51.518188Z"
    },
    "papermill": {
     "duration": 0.042018,
     "end_time": "2021-11-16T15:10:17.318101",
     "exception": false,
     "start_time": "2021-11-16T15:10:17.276083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.loc[:, ['presented_quote', 'presented_response', 'presented_response_tag']]\n",
    "y = df.loc[:, ['emotion_fact']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e241c3f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:17.383305Z",
     "iopub.status.busy": "2021-11-16T15:10:17.381167Z",
     "iopub.status.idle": "2021-11-16T15:10:17.384051Z",
     "shell.execute_reply": "2021-11-16T15:10:17.384603Z",
     "shell.execute_reply.started": "2021-11-16T15:06:51.530343Z"
    },
    "papermill": {
     "duration": 0.040467,
     "end_time": "2021-11-16T15:10:17.384750",
     "exception": false,
     "start_time": "2021-11-16T15:10:17.344283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_quotes = X_train['presented_response'].values\n",
    "X_train_responses = X_train['presented_response'].values\n",
    "X_train_responses_tag = X_train['presented_response_tag'].values\n",
    "\n",
    "X_test_quotes = X_test['presented_response'].values\n",
    "X_test_responses = X_test['presented_response'].values\n",
    "X_test_responses_tag = X_test['presented_response_tag'].values\n",
    "\n",
    "y_train = y_train['emotion_fact'].values\n",
    "y_test = y_test['emotion_fact'].values\n",
    "\n",
    "X_train_text = X_train_quotes + X_train_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c307da",
   "metadata": {
    "papermill": {
     "duration": 0.026264,
     "end_time": "2021-11-16T15:10:17.436922",
     "exception": false,
     "start_time": "2021-11-16T15:10:17.410658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce8dc21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:17.494970Z",
     "iopub.status.busy": "2021-11-16T15:10:17.494097Z",
     "iopub.status.idle": "2021-11-16T15:10:18.624762Z",
     "shell.execute_reply": "2021-11-16T15:10:18.624050Z",
     "shell.execute_reply.started": "2021-11-16T15:06:51.542162Z"
    },
    "papermill": {
     "duration": 1.16181,
     "end_time": "2021-11-16T15:10:18.624931",
     "exception": false,
     "start_time": "2021-11-16T15:10:17.463121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db5f6301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:18.696057Z",
     "iopub.status.busy": "2021-11-16T15:10:18.693257Z",
     "iopub.status.idle": "2021-11-16T15:10:19.064240Z",
     "shell.execute_reply": "2021-11-16T15:10:19.063651Z",
     "shell.execute_reply.started": "2021-11-16T15:06:52.357416Z"
    },
    "papermill": {
     "duration": 0.412193,
     "end_time": "2021-11-16T15:10:19.064389",
     "exception": false,
     "start_time": "2021-11-16T15:10:18.652196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9da503a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:19.126741Z",
     "iopub.status.busy": "2021-11-16T15:10:19.125726Z",
     "iopub.status.idle": "2021-11-16T15:10:19.130046Z",
     "shell.execute_reply": "2021-11-16T15:10:19.129515Z",
     "shell.execute_reply.started": "2021-11-16T15:06:52.665625Z"
    },
    "papermill": {
     "duration": 0.038942,
     "end_time": "2021-11-16T15:10:19.130194",
     "exception": false,
     "start_time": "2021-11-16T15:10:19.091252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bert_encode(quotes, responses, tokenizer, max_len=160):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for i in range(len(quotes)):\n",
    "        quote = tokenizer.tokenize(quotes[i])\n",
    "        response = tokenizer.tokenize(responses[i])\n",
    "            \n",
    "        quote = quote[:75]\n",
    "        response = response[:75]\n",
    "        \n",
    "        input_sequence = [\"[CLS]\"] + quote + [\"[SEP]\"] + response\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d67d1492",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:19.190818Z",
     "iopub.status.busy": "2021-11-16T15:10:19.189756Z",
     "iopub.status.idle": "2021-11-16T15:10:19.192479Z",
     "shell.execute_reply": "2021-11-16T15:10:19.193049Z",
     "shell.execute_reply.started": "2021-11-16T15:06:52.675598Z"
    },
    "papermill": {
     "duration": 0.037537,
     "end_time": "2021-11-16T15:10:19.193208",
     "exception": false,
     "start_time": "2021-11-16T15:10:19.155671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_len=512):\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    \n",
    "    out = Dense(1, activation='sigmoid')(clf_output)\n",
    "\n",
    "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(Adam(learning_rate=5.95e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14781133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:19.252213Z",
     "iopub.status.busy": "2021-11-16T15:10:19.249530Z",
     "iopub.status.idle": "2021-11-16T15:10:19.255450Z",
     "shell.execute_reply": "2021-11-16T15:10:19.254939Z",
     "shell.execute_reply.started": "2021-11-16T15:06:52.690725Z"
    },
    "papermill": {
     "duration": 0.035912,
     "end_time": "2021-11-16T15:10:19.255641",
     "exception": false,
     "start_time": "2021-11-16T15:10:19.219729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(train_input, train_labels):\n",
    "      \n",
    "    model_BERT = build_model(bert_layer, max_len=160)\n",
    "    model_BERT.summary()\n",
    "    \n",
    "    checkpoint = ModelCheckpoint('model_BERT.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    model_BERT.fit(\n",
    "        train_input, train_labels,\n",
    "        validation_split = 0.15,\n",
    "        epochs = 3,\n",
    "        callbacks=[checkpoint],\n",
    "        batch_size = 16\n",
    "    )\n",
    "    \n",
    "    return model_BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ec38d5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:10:19.313876Z",
     "iopub.status.busy": "2021-11-16T15:10:19.313102Z",
     "iopub.status.idle": "2021-11-16T15:11:04.634652Z",
     "shell.execute_reply": "2021-11-16T15:11:04.633993Z",
     "shell.execute_reply.started": "2021-11-16T15:06:52.699982Z"
    },
    "papermill": {
     "duration": 45.352672,
     "end_time": "2021-11-16T15:11:04.634857",
     "exception": false,
     "start_time": "2021-11-16T15:10:19.282185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:10:43.561549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 15:10:43.685493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 15:10:43.686850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 15:10:43.691087: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-16 15:10:43.694637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 15:10:43.695923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 15:10:43.697186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 15:10:46.529799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 15:10:46.530892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 15:10:46.531876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-16 15:10:46.532870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)\n",
    "\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf224726",
   "metadata": {
    "papermill": {
     "duration": 0.030454,
     "end_time": "2021-11-16T15:11:04.693587",
     "exception": false,
     "start_time": "2021-11-16T15:11:04.663133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Eksperimen Fitur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b754ab7a",
   "metadata": {
    "papermill": {
     "duration": 0.027087,
     "end_time": "2021-11-16T15:11:04.747474",
     "exception": false,
     "start_time": "2021-11-16T15:11:04.720387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Statement (Quote) dan Argument (Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "634b0c7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:11:04.835116Z",
     "iopub.status.busy": "2021-11-16T15:11:04.829994Z",
     "iopub.status.idle": "2021-11-16T15:11:25.569498Z",
     "shell.execute_reply": "2021-11-16T15:11:25.568747Z",
     "shell.execute_reply.started": "2021-11-16T15:07:22.828674Z"
    },
    "papermill": {
     "duration": 20.794918,
     "end_time": "2021-11-16T15:11:25.569684",
     "exception": false,
     "start_time": "2021-11-16T15:11:04.774766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_input = bert_encode(X_train_quotes, X_train_responses, tokenizer, max_len=160)\n",
    "test_input = bert_encode(X_test_quotes, X_test_responses, tokenizer, max_len=160)\n",
    "train_labels = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "645a4d65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:11:25.636105Z",
     "iopub.status.busy": "2021-11-16T15:11:25.627511Z",
     "iopub.status.idle": "2021-11-16T15:25:27.398013Z",
     "shell.execute_reply": "2021-11-16T15:25:27.396891Z",
     "shell.execute_reply.started": "2021-11-16T15:07:41.059459Z"
    },
    "papermill": {
     "duration": 841.801138,
     "end_time": "2021-11-16T15:25:27.398179",
     "exception": false,
     "start_time": "2021-11-16T15:11:25.597041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 1024)         0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1025        tf.__operators__.getitem[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 335,142,914\n",
      "Trainable params: 335,142,913\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:11:27.128943: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 299s 979ms/step - loss: 0.5012 - accuracy: 0.7475 - val_loss: 0.4688 - val_accuracy: 0.7828\n",
      "Epoch 2/3\n",
      "265/265 [==============================] - 256s 966ms/step - loss: 0.2667 - accuracy: 0.8930 - val_loss: 0.7447 - val_accuracy: 0.7145\n",
      "Epoch 3/3\n",
      "265/265 [==============================] - 256s 966ms/step - loss: 0.0569 - accuracy: 0.9823 - val_loss: 0.7607 - val_accuracy: 0.7641\n"
     ]
    }
   ],
   "source": [
    "model_BERT = train_model(train_input, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57395205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:25:27.981079Z",
     "iopub.status.busy": "2021-11-16T15:25:27.979913Z",
     "iopub.status.idle": "2021-11-16T15:25:51.119479Z",
     "shell.execute_reply": "2021-11-16T15:25:51.120328Z",
     "shell.execute_reply.started": "2021-11-16T15:08:33.216189Z"
    },
    "papermill": {
     "duration": 23.434575,
     "end_time": "2021-11-16T15:25:51.120603",
     "exception": false,
     "start_time": "2021-11-16T15:25:27.686028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       524\n",
      "           1       0.72      0.71      0.72       354\n",
      "\n",
      "    accuracy                           0.77       878\n",
      "   macro avg       0.76      0.76      0.76       878\n",
      "weighted avg       0.77      0.77      0.77       878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_pred_BERT = model_BERT.predict(test_input)\n",
    "test_pred_BERT_int = test_pred_BERT.round().astype('int')\n",
    "\n",
    "pred = test_pred_BERT_int.reshape([test_pred_BERT_int.shape[0]])\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5386530",
   "metadata": {
    "papermill": {
     "duration": 0.286022,
     "end_time": "2021-11-16T15:25:51.698206",
     "exception": false,
     "start_time": "2021-11-16T15:25:51.412184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Argument (Response) dan TAG Argument (Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7104c47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:25:52.307602Z",
     "iopub.status.busy": "2021-11-16T15:25:52.292218Z",
     "iopub.status.idle": "2021-11-16T15:26:10.097169Z",
     "shell.execute_reply": "2021-11-16T15:26:10.097735Z",
     "shell.execute_reply.started": "2021-11-16T15:08:33.217982Z"
    },
    "papermill": {
     "duration": 18.115561,
     "end_time": "2021-11-16T15:26:10.097922",
     "exception": false,
     "start_time": "2021-11-16T15:25:51.982361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_input = bert_encode(X_train_responses, X_train_responses_tag, tokenizer, max_len=160)\n",
    "test_input = bert_encode(X_test_responses, X_test_responses_tag, tokenizer, max_len=160)\n",
    "train_labels = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87cac6f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:26:10.690388Z",
     "iopub.status.busy": "2021-11-16T15:26:10.689272Z",
     "iopub.status.idle": "2021-11-16T15:39:50.209340Z",
     "shell.execute_reply": "2021-11-16T15:39:50.208616Z",
     "shell.execute_reply.started": "2021-11-16T15:08:33.219618Z"
    },
    "papermill": {
     "duration": 819.821894,
     "end_time": "2021-11-16T15:39:50.209565",
     "exception": false,
     "start_time": "2021-11-16T15:26:10.387671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None, 1024)         0           keras_layer[1][1]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        tf.__operators__.getitem_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 335,142,914\n",
      "Trainable params: 335,142,913\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/3\n",
      "265/265 [==============================] - 276s 977ms/step - loss: 0.2124 - accuracy: 0.9068 - val_loss: 0.7322 - val_accuracy: 0.7627\n",
      "Epoch 2/3\n",
      "265/265 [==============================] - 256s 967ms/step - loss: 0.0292 - accuracy: 0.9922 - val_loss: 0.8932 - val_accuracy: 0.7507\n",
      "Epoch 3/3\n",
      "265/265 [==============================] - 256s 967ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 1.0237 - val_accuracy: 0.7748\n"
     ]
    }
   ],
   "source": [
    "model_BERT = train_model(train_input, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ce29aab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T15:39:51.640381Z",
     "iopub.status.busy": "2021-11-16T15:39:51.639076Z",
     "iopub.status.idle": "2021-11-16T15:40:14.757659Z",
     "shell.execute_reply": "2021-11-16T15:40:14.758412Z",
     "shell.execute_reply.started": "2021-11-16T15:08:33.221218Z"
    },
    "papermill": {
     "duration": 23.694341,
     "end_time": "2021-11-16T15:40:14.758665",
     "exception": false,
     "start_time": "2021-11-16T15:39:51.064324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       524\n",
      "           1       0.74      0.71      0.73       354\n",
      "\n",
      "    accuracy                           0.78       878\n",
      "   macro avg       0.78      0.77      0.77       878\n",
      "weighted avg       0.78      0.78      0.78       878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_pred_BERT = model_BERT.predict(test_input)\n",
    "test_pred_BERT_int = test_pred_BERT.round().astype('int')\n",
    "\n",
    "pred = test_pred_BERT_int.reshape([test_pred_BERT_int.shape[0]])\n",
    "print(classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1818.670175,
   "end_time": "2021-11-16T15:40:18.666893",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-16T15:09:59.996718",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
