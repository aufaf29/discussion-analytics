{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Legion\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Legion\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/quotexresponse.pkl\", \"rb\")\n",
    "df = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>presented_quote</th>\n",
       "      <th>presented_response</th>\n",
       "      <th>emotion_fact</th>\n",
       "      <th>disagree_agree</th>\n",
       "      <th>plain_sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I got a good idea. however, they do tend to st...</td>\n",
       "      <td>By your own admission you havenÂ’t 'hung out' ...</td>\n",
       "      <td>feeling-based</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>unsure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Be sure to give your guns a big fat kiss tonig...</td>\n",
       "      <td>Actually, they didn't. The whole tragedy was c...</td>\n",
       "      <td>unsure</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>unsure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One of the biggest arguments against gun contr...</td>\n",
       "      <td>Not quite. To be more correct regarding govern...</td>\n",
       "      <td>fact-based</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>no_sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First of all, compare the \"B\" specimen in your...</td>\n",
       "      <td>At your service:\\nComparison\\nI could've just ...</td>\n",
       "      <td>unsure</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>unsure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are some incedents that are beyond your ...</td>\n",
       "      <td>Well yes.</td>\n",
       "      <td>feeling-based</td>\n",
       "      <td>agreement</td>\n",
       "      <td>no_sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>The ID movements form of ID states that there ...</td>\n",
       "      <td>That , of course, is the logical fallacy known...</td>\n",
       "      <td>fact-based</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>no_sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>For me, it would therefore have made no differ...</td>\n",
       "      <td>It logically follows from the moral foundation...</td>\n",
       "      <td>feeling-based</td>\n",
       "      <td>agreement</td>\n",
       "      <td>no_sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>good thing this argument has never been done!....</td>\n",
       "      <td>And teen sex doesn't, by the very nature of it...</td>\n",
       "      <td>feeling-based</td>\n",
       "      <td>unsure</td>\n",
       "      <td>no_sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>I know one thing, anything that happens, polit...</td>\n",
       "      <td>Wasn't sinjin crowing about his plans to take ...</td>\n",
       "      <td>feeling-based</td>\n",
       "      <td>unsure</td>\n",
       "      <td>no_sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>I enjoy Botany more than most things and I hav...</td>\n",
       "      <td>Hi Smallax, welcome to the forum. I did a sear...</td>\n",
       "      <td>fact-based</td>\n",
       "      <td>agreement</td>\n",
       "      <td>no_sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9982 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        presented_quote  \\\n",
       "0     I got a good idea. however, they do tend to st...   \n",
       "1     Be sure to give your guns a big fat kiss tonig...   \n",
       "2     One of the biggest arguments against gun contr...   \n",
       "3     First of all, compare the \"B\" specimen in your...   \n",
       "4     There are some incedents that are beyond your ...   \n",
       "...                                                 ...   \n",
       "9977  The ID movements form of ID states that there ...   \n",
       "9978  For me, it would therefore have made no differ...   \n",
       "9979  good thing this argument has never been done!....   \n",
       "9980  I know one thing, anything that happens, polit...   \n",
       "9981  I enjoy Botany more than most things and I hav...   \n",
       "\n",
       "                                     presented_response   emotion_fact  \\\n",
       "0     By your own admission you havenÂ’t 'hung out' ...  feeling-based   \n",
       "1     Actually, they didn't. The whole tragedy was c...         unsure   \n",
       "2     Not quite. To be more correct regarding govern...     fact-based   \n",
       "3     At your service:\\nComparison\\nI could've just ...         unsure   \n",
       "4                                             Well yes.  feeling-based   \n",
       "...                                                 ...            ...   \n",
       "9977  That , of course, is the logical fallacy known...     fact-based   \n",
       "9978  It logically follows from the moral foundation...  feeling-based   \n",
       "9979  And teen sex doesn't, by the very nature of it...  feeling-based   \n",
       "9980  Wasn't sinjin crowing about his plans to take ...  feeling-based   \n",
       "9981  Hi Smallax, welcome to the forum. I did a sear...     fact-based   \n",
       "\n",
       "     disagree_agree plain_sarcasm  \n",
       "0      disagreement        unsure  \n",
       "1      disagreement        unsure  \n",
       "2      disagreement    no_sarcasm  \n",
       "3      disagreement        unsure  \n",
       "4         agreement    no_sarcasm  \n",
       "...             ...           ...  \n",
       "9977   disagreement    no_sarcasm  \n",
       "9978      agreement    no_sarcasm  \n",
       "9979         unsure    no_sarcasm  \n",
       "9980         unsure    no_sarcasm  \n",
       "9981      agreement    no_sarcasm  \n",
       "\n",
       "[9982 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got a good idea. however, they do tend to stay with their own.\n",
      "\n",
      "By your own admission you havenÂ’t 'hung out' with stoners for a while and you're making generalisations about them to people who do spend a lot of time with stoners?\n",
      "\n",
      "Be sure to give your guns a big fat kiss tonight before you go to bed tonight 'cuz guns did really good today.\n",
      "\n",
      "Actually, they didn't. The whole tragedy was caused by gun control. If even one student was packing when that occured, 33 lives could have been saved. But no, more victims of botched laws and corrupt politicians.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = df.loc[:1, ['presented_quote', 'presented_response']].to_numpy()\n",
    "text = text.reshape([4,])\n",
    "for i in range(text.shape[0]):\n",
    "    print(text[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "    \n",
    "def lemmatize_sentence(sentence):\n",
    "\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    \n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "def sentence_pos_tag(sentence):\n",
    "    text = word_tokenize(sentence)\n",
    "    pos_tag = nltk.pos_tag(text)\n",
    "    pos_tag_res = ''\n",
    "    for i in range(len(pos_tag)):\n",
    "        pos_tag_res += pos_tag[i][1]\n",
    "        pos_tag_res += ' ' if i != len(sentence)-1 else '' \n",
    "    return pos_tag_res\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\" \\d+ \", \" \", text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = re.sub(r\"[^a-z ]\", \"\", text)\n",
    "    text = re.sub(r\"  \", \" \", text)\n",
    "    text = lemmatize_sentence(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got a good idea. however, they do tend to stay with their own.\n",
      "i get a good idea however they do tend to stay with their own\n",
      "\n",
      "By your own admission you havenÂ’t 'hung out' with stoners for a while and you're making generalisations about them to people who do spend a lot of time with stoners?\n",
      "by your own admission you havent hang out with stoner for a while and youre making generalisation about them to people who do spend a lot of time with stoner\n",
      "\n",
      "Be sure to give your guns a big fat kiss tonight before you go to bed tonight 'cuz guns did really good today.\n",
      "be sure to give your gun a big fat kiss tonight before you go to bed tonight cuz gun do really good today\n",
      "\n",
      "Actually, they didn't. The whole tragedy was caused by gun control. If even one student was packing when that occured, 33 lives could have been saved. But no, more victims of botched laws and corrupt politicians.\n",
      "actually they didnt the whole tragedy be cause by gun control if even one student be pack when that occur life could have be save but no more victim of botch law and corrupt politician\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(text.shape[0]):\n",
    "    print(text[i])\n",
    "    text[i] = preprocessing(text[i])\n",
    "    \n",
    "    print(text[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('actually', 'RB'), ('they', 'PRP'), ('didnt', 'VBP'), ('the', 'DT'), ('whole', 'JJ'), ('tragedy', 'NN'), ('be', 'VB'), ('cause', 'VBN'), ('by', 'IN'), ('gun', 'NN'), ('control', 'NN'), ('if', 'IN'), ('even', 'RB'), ('one', 'CD'), ('student', 'NN'), ('be', 'VB'), ('pack', 'VBN'), ('when', 'WRB'), ('that', 'DT'), ('occur', 'VBP'), ('life', 'NN'), ('could', 'MD'), ('have', 'VB'), ('be', 'VB'), ('save', 'VBN'), ('but', 'CC'), ('no', 'DT'), ('more', 'JJR'), ('victim', 'NN'), ('of', 'IN'), ('botch', 'NN'), ('law', 'NN'), ('and', 'CC'), ('corrupt', 'JJ'), ('politician', 'NN')]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'RB PRP VBP DT JJ NN VB VBN IN NN NN IN RB CD NN VB VBN WRB DT VBP NN MD VB VB VBN CC DT JJR NN IN NN NN CC JJ NN'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize('actually they didnt the whole tragedy be cause by gun control if even one student be pack when that occur life could have be save but no more victim of botch law and corrupt politician')\n",
    "pos_tag = nltk.pos_tag(text)\n",
    "print(pos_tag)\n",
    "pos_tag = sentence_pos_tag(pos_tag)\n",
    "pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>presented_quote</th>\n",
       "      <th>presented_response</th>\n",
       "      <th>emotion_fact</th>\n",
       "      <th>disagree_agree</th>\n",
       "      <th>plain_sarcasm</th>\n",
       "      <th>presented_quote_tag</th>\n",
       "      <th>presented_response_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i get a good idea however they do tend to stay...</td>\n",
       "      <td>by your own admission you havent hang out with...</td>\n",
       "      <td>feeling-based</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>unsure</td>\n",
       "      <td>NN VBP DT JJ NN RB PRP VBP VB TO VB IN PRP$ JJ</td>\n",
       "      <td>IN PRP$ JJ NN PRP VBP VB RP IN NN IN DT NN CC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be sure to give your gun a big fat kiss tonigh...</td>\n",
       "      <td>actually they didnt the whole tragedy be cause...</td>\n",
       "      <td>unsure</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>unsure</td>\n",
       "      <td>VB JJ TO VB PRP$ NN DT JJ NN NN NN IN PRP VBP ...</td>\n",
       "      <td>RB PRP VBP DT JJ NN VB VBN IN NN NN IN RB CD N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one of the big argument against gun control be...</td>\n",
       "      <td>not quite to be more correct regard government...</td>\n",
       "      <td>fact-based</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>no_sarcasm</td>\n",
       "      <td>CD IN DT JJ NN IN NN NN VB IN IN DT NN VB RB J...</td>\n",
       "      <td>RB RB TO VB RBR JJ JJ NN CC VB DT NN TO VB NN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first of all compare the b specimen in your fo...</td>\n",
       "      <td>at your servicecomparisoni couldve just circle...</td>\n",
       "      <td>unsure</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>unsure</td>\n",
       "      <td>RB IN DT VBP DT NN NNS IN PRP$ NN NN TO DT JJ ...</td>\n",
       "      <td>IN PRP$ JJ NN RB VB DT JJ NN CC DT VBP PRP JJ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there be some incedents that be beyond your co...</td>\n",
       "      <td>well yes</td>\n",
       "      <td>feeling-based</td>\n",
       "      <td>agreement</td>\n",
       "      <td>no_sarcasm</td>\n",
       "      <td>RB VB DT NNS WDT VB IN PRP$ NN IN PRP VBP DT N...</td>\n",
       "      <td>RB RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>the id movement form of id state that there be...</td>\n",
       "      <td>that of course be the logical fallacy know as ...</td>\n",
       "      <td>fact-based</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>no_sarcasm</td>\n",
       "      <td>DT JJ NN NN IN JJ NN IN EX VB JJ NN IN DT NN I...</td>\n",
       "      <td>DT IN NN VB DT JJ NN VBP IN JJ NN DT NN PRP VB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>for me it would therefore have make no differe...</td>\n",
       "      <td>it logically follow from the moral foundation ...</td>\n",
       "      <td>feeling-based</td>\n",
       "      <td>agreement</td>\n",
       "      <td>no_sarcasm</td>\n",
       "      <td>IN PRP PRP MD RB VB NN DT NN IN NNS VBP VB VBN...</td>\n",
       "      <td>PRP RB VBP IN DT JJ NN VBN RP CC PRP VBP TO JJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>good thing this argument have never be doneoh ...</td>\n",
       "      <td>and teen sex doesnt by the very nature of its ...</td>\n",
       "      <td>feeling-based</td>\n",
       "      <td>unsure</td>\n",
       "      <td>no_sarcasm</td>\n",
       "      <td>JJ NN DT NN VBP RB VB JJ NN WDT VBZ PRP MD VB ...</td>\n",
       "      <td>CC JJ NN NN IN DT JJ NN IN PRP$ NN NN IN NN DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>i know one thing anything that happen politica...</td>\n",
       "      <td>wasnt sinjin crow about his plan to take the f...</td>\n",
       "      <td>feeling-based</td>\n",
       "      <td>unsure</td>\n",
       "      <td>no_sarcasm</td>\n",
       "      <td>NN VBP CD NN NN WDT VBZ RB JJ NNS MD VB PRP RB...</td>\n",
       "      <td>NN NN NN IN PRP$ NN TO VB DT NN NN CC NN TO DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>i enjoy botany more than most thing and i have...</td>\n",
       "      <td>hi smallax welcome to the forum i do a search ...</td>\n",
       "      <td>fact-based</td>\n",
       "      <td>agreement</td>\n",
       "      <td>no_sarcasm</td>\n",
       "      <td>NN VBP NN JJR IN JJS NN CC NN VBP VBN IN DT NN...</td>\n",
       "      <td>NN VBZ JJ TO DT NN NN VBP DT NN CC VBP VBN DT ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        presented_quote  \\\n",
       "0     i get a good idea however they do tend to stay...   \n",
       "1     be sure to give your gun a big fat kiss tonigh...   \n",
       "2     one of the big argument against gun control be...   \n",
       "3     first of all compare the b specimen in your fo...   \n",
       "4     there be some incedents that be beyond your co...   \n",
       "...                                                 ...   \n",
       "9977  the id movement form of id state that there be...   \n",
       "9978  for me it would therefore have make no differe...   \n",
       "9979  good thing this argument have never be doneoh ...   \n",
       "9980  i know one thing anything that happen politica...   \n",
       "9981  i enjoy botany more than most thing and i have...   \n",
       "\n",
       "                                     presented_response   emotion_fact  \\\n",
       "0     by your own admission you havent hang out with...  feeling-based   \n",
       "1     actually they didnt the whole tragedy be cause...         unsure   \n",
       "2     not quite to be more correct regard government...     fact-based   \n",
       "3     at your servicecomparisoni couldve just circle...         unsure   \n",
       "4                                              well yes  feeling-based   \n",
       "...                                                 ...            ...   \n",
       "9977  that of course be the logical fallacy know as ...     fact-based   \n",
       "9978  it logically follow from the moral foundation ...  feeling-based   \n",
       "9979  and teen sex doesnt by the very nature of its ...  feeling-based   \n",
       "9980  wasnt sinjin crow about his plan to take the f...  feeling-based   \n",
       "9981  hi smallax welcome to the forum i do a search ...     fact-based   \n",
       "\n",
       "     disagree_agree plain_sarcasm  \\\n",
       "0      disagreement        unsure   \n",
       "1      disagreement        unsure   \n",
       "2      disagreement    no_sarcasm   \n",
       "3      disagreement        unsure   \n",
       "4         agreement    no_sarcasm   \n",
       "...             ...           ...   \n",
       "9977   disagreement    no_sarcasm   \n",
       "9978      agreement    no_sarcasm   \n",
       "9979         unsure    no_sarcasm   \n",
       "9980         unsure    no_sarcasm   \n",
       "9981      agreement    no_sarcasm   \n",
       "\n",
       "                                    presented_quote_tag  \\\n",
       "0       NN VBP DT JJ NN RB PRP VBP VB TO VB IN PRP$ JJ    \n",
       "1     VB JJ TO VB PRP$ NN DT JJ NN NN NN IN PRP VBP ...   \n",
       "2     CD IN DT JJ NN IN NN NN VB IN IN DT NN VB RB J...   \n",
       "3     RB IN DT VBP DT NN NNS IN PRP$ NN NN TO DT JJ ...   \n",
       "4     RB VB DT NNS WDT VB IN PRP$ NN IN PRP VBP DT N...   \n",
       "...                                                 ...   \n",
       "9977  DT JJ NN NN IN JJ NN IN EX VB JJ NN IN DT NN I...   \n",
       "9978  IN PRP PRP MD RB VB NN DT NN IN NNS VBP VB VBN...   \n",
       "9979  JJ NN DT NN VBP RB VB JJ NN WDT VBZ PRP MD VB ...   \n",
       "9980  NN VBP CD NN NN WDT VBZ RB JJ NNS MD VB PRP RB...   \n",
       "9981  NN VBP NN JJR IN JJS NN CC NN VBP VBN IN DT NN...   \n",
       "\n",
       "                                 presented_response_tag  \n",
       "0     IN PRP$ JJ NN PRP VBP VB RP IN NN IN DT NN CC ...  \n",
       "1     RB PRP VBP DT JJ NN VB VBN IN NN NN IN RB CD N...  \n",
       "2     RB RB TO VB RBR JJ JJ NN CC VB DT NN TO VB NN ...  \n",
       "3     IN PRP$ JJ NN RB VB DT JJ NN CC DT VBP PRP JJ ...  \n",
       "4                                                RB RB   \n",
       "...                                                 ...  \n",
       "9977  DT IN NN VB DT JJ NN VBP IN JJ NN DT NN PRP VB...  \n",
       "9978  PRP RB VBP IN DT JJ NN VBN RP CC PRP VBP TO JJ...  \n",
       "9979  CC JJ NN NN IN DT JJ NN IN PRP$ NN NN IN NN DT...  \n",
       "9980  NN NN NN IN PRP$ NN TO VB DT NN NN CC NN TO DT...  \n",
       "9981  NN VBZ JJ TO DT NN NN VBP DT NN CC VBP VBN DT ...  \n",
       "\n",
       "[9982 rows x 7 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['presented_quote'] = df['presented_quote'].apply(lambda text: preprocessing(text))\n",
    "df['presented_response'] = df['presented_response'].apply(lambda text: preprocessing(text))\n",
    "df['presented_quote_tag'] = df['presented_quote'].apply(lambda text: sentence_pos_tag(text))\n",
    "df['presented_response_tag'] = df['presented_response'].apply(lambda text: sentence_pos_tag(text))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/quotexresponseprocessed.pkl\", \"wb\")\n",
    "pickle.dump(df, file)\n",
    "file.close()\n",
    "\n",
    "# RT remove, mention remove, Same class domination remove, url remove"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb6d253a963df6dbc337acb2f379a4826e68aeb1a86c1b88229d03fac46dc808"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
